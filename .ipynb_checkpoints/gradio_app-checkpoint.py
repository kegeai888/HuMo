#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import gradio as gr
import os
import json
import tempfile
import shutil
from pathlib import Path
import torch
import sys
from typing import Optional, Tuple, List
import numpy as np
from PIL import Image
import mediapy
import time
import time
import traceback

# æ·»åŠ é¡¹ç›®è·¯å¾„
path_to_insert = "humo"
if path_to_insert not in sys.path:
    sys.path.insert(0, path_to_insert)

from common.config import load_config, create_object
from common.distributed import get_device, get_global_rank, init_torch

class HuMoGradioApp:
    def __init__(self):
        self.generator = None
        self.config = None
        self.temp_dir = tempfile.mkdtemp()
        self.progress = 0
        self.is_generating = False
        self.progress = 0
        self.is_generating = False
        
    def load_model(self, model_path: str = "./weights/HuMo/HuMo-1.7B"):
        """åŠ è½½HuMoæ¨¡å‹"""
        try:
            if not os.path.exists(model_path):
                return f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}"
            
            # åˆå§‹åŒ–é…ç½® generate.yamlæ˜¯17B
            config_path = "humo/configs/inference/generate_1_7B.yaml"
            if not os.path.exists(config_path):
                return f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}"
            
            # åŠ è½½é…ç½®
            self.config = load_config(config_path, [])
            self.config.dit.checkpoint_dir = model_path
            
            # åœ¨å•æœºæ¨¡å¼ä¸‹ç¦ç”¨åºåˆ—å¹¶è¡Œ
            import torch.distributed as dist
            if not dist.is_initialized() or dist.get_world_size() == 1:
                self.config.dit.sp_size = 1
                self.config.generation.sequence_parallel = 1
                print("ğŸ”§ å•æœºæ¨¡å¼ï¼šå·²ç¦ç”¨åºåˆ—å¹¶è¡Œ")
            
            # åˆå§‹åŒ–torch
            init_torch(cudnn_benchmark=False)
            
            # åˆ›å»ºç”Ÿæˆå™¨
            self.generator = create_object(self.config)

            # é…ç½®æ¨¡å‹ç»„ä»¶ï¼ˆåŒ…æ‹¬vaeï¼‰
            self.generator.configure_models()
            
            return "âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼"
        except Exception as e:
            traceback.print_exc()
            return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
    
    def update_progress(self) -> float:
        """æ›´æ–°è¿›åº¦æ¡"""
        if not self.is_generating:
            return 0
        self.progress += 1
        # æ¨¡æ‹Ÿè¿›åº¦ï¼Œæœ€å¤§å€¼ä¸º99%ï¼Œç•™1%ç»™æœ€ç»ˆå¤„ç†
        progress_value = min(99, self.progress)
        return progress_value
    
    def update_progress(self) -> float:
        """æ›´æ–°è¿›åº¦æ¡"""
        if not self.is_generating:
            return 0
        self.progress += 1
        # æ¨¡æ‹Ÿè¿›åº¦ï¼Œæœ€å¤§å€¼ä¸º99%ï¼Œç•™1%ç»™æœ€ç»ˆå¤„ç†
        progress_value = min(99, self.progress)
        return progress_value
    
    def generate_video(
        self,
        prompt: str,
        ref_image: Optional[Image.Image] = None,
        audio_file: Optional[str] = None,
        mode: str = "TA",
        frames: int = 97,
        height: int = 720,
        width: int = 1280,
        scale_a: float = 5.5,
        scale_t: float = 5.0,
        sampling_steps: int = 50,
        seed: int = 666666,
        fps: int = 25
    ) -> Tuple[str, str, float]:
        """ç”Ÿæˆè§†é¢‘"""
        try:
            # é‡ç½®è¿›åº¦
            self.progress = 0
            self.is_generating = True
            
            if self.generator is None:
                self.is_generating = False
                return None, "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹", 0
            
            if not prompt.strip():
                self.is_generating = False
                return None, "âŒ è¯·è¾“å…¥æ–‡æœ¬æç¤º", 0
            
            # å‡†å¤‡è¾“å‡ºç›®å½•
            output_dir = os.path.join(self.temp_dir, "output")
            os.makedirs(output_dir, exist_ok=True)
            
            # åˆ›å»ºä¸´æ—¶æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶
            test_case = {
                "case_1": {
                    "text": prompt,
                    "ref_img": None,
                    "audio": None,
                    "itemname": "gradio_generated"
                }
            }
            
            # å¤„ç†å‚è€ƒå›¾åƒ
            if ref_image is not None and mode == "TIA":
                img_path = os.path.join(self.temp_dir, "ref_image.png")
                ref_image.save(img_path)
                test_case["case_1"]["ref_img"] = img_path
            elif mode == "TIA" and ref_image is None:
                self.is_generating = False
                return None, "âŒ TIAæ¨¡å¼éœ€è¦æä¾›å‚è€ƒå›¾åƒ", 0
            
            # å¤„ç†éŸ³é¢‘æ–‡ä»¶
            if audio_file is not None:
                audio_path = os.path.join(self.temp_dir, "audio.wav")
                shutil.copy2(audio_file, audio_path)
                test_case["case_1"]["audio"] = audio_path
            
            # ä¿å­˜æµ‹è¯•ç”¨ä¾‹
            test_case_path = os.path.join(self.temp_dir, "test_case.json")
            with open(test_case_path, 'w', encoding='utf-8') as f:
                json.dump(test_case, f, ensure_ascii=False, indent=2)
            
            # æ›´æ–°é…ç½®
            self.config.generation.mode = mode
            self.config.generation.frames = frames
            self.config.generation.height = height
            self.config.generation.width = width
            self.config.generation.scale_a = scale_a
            self.config.generation.scale_t = scale_t
            self.config.diffusion.timesteps.sampling.steps = sampling_steps
            self.config.generation.seed = seed
            self.config.generation.fps = fps
            self.config.generation.positive_prompt = test_case_path
            self.config.generation.output.dir = output_dir
            
            # ç”Ÿæˆè§†é¢‘
            self.generator.inference_loop()
            
            # æŸ¥æ‰¾ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶
            output_files = list(Path(output_dir).glob("*.mp4"))
            self.is_generating = False
            self.progress = 100  # è®¾ç½®ä¸º100%å®Œæˆ
            
            if output_files:
                video_path = str(output_files[0])
                return video_path, "âœ… è§†é¢‘ç”ŸæˆæˆåŠŸï¼", 100
            else:
                return None, "âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶", 0
                
        except Exception as e:
            traceback.print_exc()
            self.is_generating = False
            return None, f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}", 0
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)

# åˆ›å»ºåº”ç”¨å®ä¾‹
app = HuMoGradioApp()

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    with gr.Blocks(title="HuMo è§†é¢‘ç”Ÿæˆå™¨", theme=gr.themes.Soft()) as interface:
        gr.Markdown("""
        # ğŸ¬ HuMo å¤šæ¨¡æ€è§†é¢‘ç”Ÿæˆå™¨
        
        åŸºäºæ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘è¾“å…¥ç”Ÿæˆé«˜è´¨é‡çš„äººç±»è§†é¢‘
        """)
        
        # æ¨¡å‹é…ç½®éƒ¨åˆ† - ç®€åŒ–å¸ƒå±€
        with gr.Row():
            with gr.Column(scale=4):
                model_path = gr.Textbox(
                    label="æ¨¡å‹è·¯å¾„",
                    # 17Bå¸¦ä¸åŠ¨
                    value="./weights/HuMo/HuMo-1.7B",
                    placeholder="è¯·è¾“å…¥HuMoæ¨¡å‹è·¯å¾„",
                    show_label=True
                )
            with gr.Column(scale=1):
                load_btn = gr.Button("ğŸ”„ åŠ è½½æ¨¡å‹", variant="primary")
        
        model_status = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", interactive=False)
        
        # ä¸»è¦è¾“å…¥éƒ¨åˆ† - ä½¿ç”¨æ ‡ç­¾é¡µåŒºåˆ†åŸºæœ¬è®¾ç½®å’Œé«˜çº§å‚æ•°
        with gr.Tabs() as tabs:
            # åŸºæœ¬è®¾ç½®æ ‡ç­¾é¡µ - åªæ˜¾ç¤ºæ ¸å¿ƒå‚æ•°
            with gr.TabItem("åŸºæœ¬è®¾ç½®"):
                with gr.Row():
                    with gr.Column(scale=2):
                        # æ ¸å¿ƒå‚æ•°ï¼šæ–‡æœ¬æç¤º
                        prompt = gr.Textbox(
                            label="æ–‡æœ¬æç¤º (å¿…å¡«)",
                            placeholder="æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„è§†é¢‘å†…å®¹...",
                            lines=3
                        )
                        
                        # æ ¸å¿ƒå‚æ•°ï¼šç”Ÿæˆæ¨¡å¼
                        mode = gr.Radio(
                            choices=["TA", "TIA"],
                            value="TA",  # é»˜è®¤ä½¿ç”¨TAæ¨¡å¼ï¼Œä¸éœ€è¦å‚è€ƒå›¾åƒ
                            label="ç”Ÿæˆæ¨¡å¼",
                            info="TA: æ–‡æœ¬+éŸ³é¢‘, TIA: æ–‡æœ¬+å›¾åƒ+éŸ³é¢‘"
                        )
                        
                        # æ ¸å¿ƒå‚æ•°ï¼šå‚è€ƒå›¾åƒå’ŒéŸ³é¢‘
                        with gr.Row():
                            with gr.Column(scale=1):
                                ref_image = gr.Image(
                                    label="å‚è€ƒå›¾åƒ (TIAæ¨¡å¼éœ€è¦)",
                                    type="pil",
                                    visible=False  # é»˜è®¤éšè—ï¼Œåªåœ¨TIAæ¨¡å¼ä¸‹æ˜¾ç¤º
                                )
                            
                            with gr.Column(scale=1):
                                audio_file = gr.Audio(
                                    label="éŸ³é¢‘æ–‡ä»¶ (å¯é€‰)",
                                    type="filepath"
                                )
                    
                    # ç¤ºä¾‹å’Œç”ŸæˆæŒ‰é’®
                    with gr.Column(scale=1):
                        # æ·»åŠ ä¸€äº›ç¤ºä¾‹æç¤º
                        gr.Markdown("### ç¤ºä¾‹æç¤º")
                        example_prompts = gr.Dataset(
                            components=[prompt],
                            samples=[
                                ["A person dancing energetically to upbeat music"],
                                ["Someone speaking confidently in a business meeting"],
                                ["A person playing guitar with passion"]
                            ],
                            label="ç‚¹å‡»åŠ è½½ç¤ºä¾‹æç¤º"
                        )
                        
                        # ç”ŸæˆæŒ‰é’®
                        generate_btn = gr.Button("ğŸ¬ ç”Ÿæˆè§†é¢‘", variant="primary", size="lg")
            
            # é«˜çº§å‚æ•°æ ‡ç­¾é¡µ - åŒ…å«æ‰€æœ‰å¯è°ƒæ•´çš„å‚æ•°
            with gr.TabItem("é«˜çº§å‚æ•°"):
                with gr.Row():
                    with gr.Column():
                        # è§†é¢‘å‚æ•°æŠ˜å é¢æ¿
                        with gr.Accordion("è§†é¢‘å‚æ•°", open=False):
                            with gr.Row():
                                frames = gr.Slider(
                                    minimum=25, maximum=97, value=97, step=4,
                                    label="è§†é¢‘å¸§æ•°",
                                    info="å¸§æ•°è¶Šå¤šè§†é¢‘è¶Šé•¿ï¼Œä½†ç”Ÿæˆæ—¶é—´ä¹Ÿè¶Šé•¿"
                                )
                                fps = gr.Slider(
                                    minimum=15, maximum=30, value=25, step=1,
                                    label="å¸§ç‡ (FPS)",
                                    info="æ¯ç§’æ˜¾ç¤ºçš„å¸§æ•°ï¼Œå½±å“è§†é¢‘æµç•…åº¦"
                                )
                            
                            with gr.Row():
                                height = gr.Slider(
                                    minimum=480, maximum=720, value=720, step=8,
                                    label="è§†é¢‘é«˜åº¦",
                                    info="720pè´¨é‡æ›´å¥½ï¼Œ480pé€Ÿåº¦æ›´å¿«"
                                )
                                width = gr.Slider(
                                    minimum=832, maximum=1280, value=1280, step=8,
                                    label="è§†é¢‘å®½åº¦",
                                    info="ä¸é«˜åº¦å¯¹åº”çš„å®½åº¦è®¾ç½®"
                                )
                        
                        # ç”Ÿæˆå‚æ•°æŠ˜å é¢æ¿
                        with gr.Accordion("ç”Ÿæˆå‚æ•°", open=False):
                            with gr.Row():
                                scale_a = gr.Slider(
                                    minimum=1.0, maximum=10.0, value=5.5, step=0.1,
                                    label="éŸ³é¢‘å¼•å¯¼å¼ºåº¦", 
                                    info="è¶Šé«˜éŸ³é¢‘åŒæ­¥è¶Šå¥½ï¼Œæ¨èå€¼ï¼š5.0-6.0"
                                )
                                scale_t = gr.Slider(
                                    minimum=1.0, maximum=10.0, value=5.0, step=0.1,
                                    label="æ–‡æœ¬å¼•å¯¼å¼ºåº¦", 
                                    info="è¶Šé«˜è¶Šéµå¾ªæ–‡æœ¬æç¤ºï¼Œæ¨èå€¼ï¼š4.0-6.0"
                                )
                            
                            with gr.Row():
                                sampling_steps = gr.Slider(
                                    minimum=20, maximum=100, value=50, step=5,
                                    label="é‡‡æ ·æ­¥æ•°", 
                                    info="æ›´å¤šæ­¥æ•°è´¨é‡æ›´å¥½ä½†æ›´æ…¢ï¼Œæ¨èå€¼ï¼š30-50"
                                )
                                seed = gr.Number(
                                    label="éšæœºç§å­",
                                    value=-1,
                                    precision=0,
                                    info="-1ä¸ºéšæœºç§å­ï¼Œå›ºå®šç§å­å¯é‡ç°ç»“æœ"
                                )
        
        # è¿›åº¦æ˜¾ç¤º
        progress_bar = gr.Progress()
        
        # è¾“å‡ºéƒ¨åˆ†
        with gr.Row():
            with gr.Column():
                output_video = gr.Video(
                    label="ç”Ÿæˆçš„è§†é¢‘",
                    height=400
                )
                status_text = gr.Textbox(
                    label="ç”ŸæˆçŠ¶æ€",
                    interactive=False,
                    lines=2
                )
        
        # äº‹ä»¶å¤„ç†
        def load_model_wrapper(model_path):
            return app.load_model(model_path)
        
        def generate_video_wrapper(prompt, ref_image, audio_file, mode, frames, height, width, 
                                 scale_a, scale_t, sampling_steps, seed, fps, progress=gr.Progress()):
            progress(0, desc="å‡†å¤‡ç”Ÿæˆ...")
            
            # åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°æ¥æ›´æ–°è¿›åº¦
            def progress_tracker():
                while app.is_generating:
                    progress_value = app.update_progress()
                    progress(progress_value/100)
                    time.sleep(0.5)
                    yield progress_value
            
            # å¯åŠ¨è¿›åº¦æ›´æ–°
            progress_gen = progress_tracker()
            
            # ç”Ÿæˆè§†é¢‘
            video_path, status, final_progress = app.generate_video(
                prompt, ref_image, audio_file, mode, frames, height, width,
                scale_a, scale_t, sampling_steps, seed, fps
            )
            
            # è®¾ç½®æœ€ç»ˆè¿›åº¦
            progress(final_progress/100)
            
            return video_path, status
        
        # æ¨¡å¼åˆ‡æ¢æ—¶æ˜¾ç¤º/éšè—å‚è€ƒå›¾åƒè¾“å…¥
        def update_ref_image_visibility(mode):
            return gr.update(visible=(mode == "TIA"))
        
        # å¤„ç†ç¤ºä¾‹æç¤ºé€‰æ‹©
        def load_example_prompt(evt: gr.SelectData):
            return evt.value[0]  # è¿”å›é€‰ä¸­çš„ç¤ºä¾‹æ–‡æœ¬
            
        # ç»‘å®šäº‹ä»¶
        load_btn.click(
            fn=load_model_wrapper,
            inputs=[model_path],
            outputs=[model_status]
        )
        
        mode.change(
            fn=update_ref_image_visibility,
            inputs=[mode],
            outputs=[ref_image]
        )

        # æ·»åŠ ç¤ºä¾‹æç¤ºé€‰æ‹©äº‹ä»¶
        example_prompts.select(
            fn=load_example_prompt,
            inputs=[],
            outputs=[prompt]
        )
        
        generate_btn.click(
            fn=generate_video_wrapper,
            inputs=[prompt, ref_image, audio_file, mode, frames, height, width,
                   scale_a, scale_t, sampling_steps, seed, fps],
            outputs=[output_video, status_text]
        )
        
        # æ·»åŠ ç¤ºä¾‹å’Œå¸®åŠ©ä¿¡æ¯
        with gr.Accordion("ğŸ’¡ ä½¿ç”¨å¸®åŠ©", open=False):
            gr.Markdown("""
            ## å¿«é€Ÿå…¥é—¨æŒ‡å—
            
            1. **åŠ è½½æ¨¡å‹**: é¦–å…ˆç‚¹å‡»"åŠ è½½æ¨¡å‹"æŒ‰é’®ï¼Œç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®
            2. **é€‰æ‹©æ¨¡å¼**: 
               - **TAæ¨¡å¼**: ä»…éœ€æ–‡æœ¬å’ŒéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
               - **TIAæ¨¡å¼**: éœ€è¦æ–‡æœ¬ã€å‚è€ƒå›¾åƒå’ŒéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
            3. **è¾“å…¥æç¤º**: è¯¦ç»†æè¿°æ‚¨æƒ³è¦ç”Ÿæˆçš„è§†é¢‘å†…å®¹
            4. **ä¸Šä¼ æ–‡ä»¶**: æ ¹æ®éœ€è¦ä¸Šä¼ å‚è€ƒå›¾åƒå’Œ/æˆ–éŸ³é¢‘æ–‡ä»¶
            5. **ç‚¹å‡»ç”Ÿæˆ**: ç­‰å¾…è§†é¢‘ç”Ÿæˆå®Œæˆ
            
            ## æç¤ºæŠ€å·§
            
            ### é«˜æ•ˆæ–‡æœ¬æç¤ºï¼š
            - ä½¿ç”¨å…·ä½“ã€è¯¦ç»†çš„æè¿°ï¼ˆå¦‚"A young woman with blonde hair dancing energetically to pop music"ï¼‰
            - åŒ…å«åŠ¨ä½œã€è¡¨æƒ…å’Œåœºæ™¯ç»†èŠ‚ï¼ˆå¦‚"A man smiling and speaking confidently in a bright office setting"ï¼‰
            - æè¿°æƒ…æ„Ÿå’Œæ°›å›´ï¼ˆå¦‚"A person playing guitar passionately with eyes closed in a dimly lit room"ï¼‰
            
            ### å‚æ•°è°ƒæ•´å»ºè®®ï¼š
            - **éŸ³é¢‘å¼•å¯¼å¼ºåº¦ (scale_a)**: 5.0-6.0 é€‚åˆå¤§å¤šæ•°æƒ…å†µï¼Œæ›´é«˜å€¼ä½¿åŠ¨ä½œæ›´ç´§å¯†è·ŸéšéŸ³é¢‘
            - **æ–‡æœ¬å¼•å¯¼å¼ºåº¦ (scale_t)**: 4.0-6.0 å¹³è¡¡åˆ›æ„å’Œå‡†ç¡®æ€§ï¼Œæ›´é«˜å€¼ä½¿ç”Ÿæˆæ›´ç¬¦åˆæ–‡æœ¬æè¿°
            - **é‡‡æ ·æ­¥æ•°**: 30-50 å¹³è¡¡è´¨é‡å’Œé€Ÿåº¦ï¼Œæ›´å¤šæ­¥æ•°ç”Ÿæˆè´¨é‡æ›´é«˜ä½†è€—æ—¶æ›´é•¿
            - **è§†é¢‘åˆ†è¾¨ç‡**: 720p è´¨é‡æ›´å¥½ï¼Œ480p é€Ÿåº¦æ›´å¿«
            - **å¸§æ•°**: 97å¸§é€‚åˆå¤§å¤šæ•°åœºæ™¯ï¼Œå‡å°‘å¸§æ•°å¯åŠ å¿«ç”Ÿæˆé€Ÿåº¦
            
            ### å¸¸è§é—®é¢˜è§£ç­”ï¼š
            - **ç”Ÿæˆå¤±è´¥**: æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿TIAæ¨¡å¼ä¸‹æä¾›äº†å‚è€ƒå›¾åƒ
            - **è§†é¢‘è´¨é‡ä¸ä½³**: å°è¯•å¢åŠ é‡‡æ ·æ­¥æ•°ï¼Œè°ƒæ•´æ–‡æœ¬å’ŒéŸ³é¢‘å¼•å¯¼å¼ºåº¦
            - **åŠ¨ä½œä¸è‡ªç„¶**: è°ƒæ•´éŸ³é¢‘å¼•å¯¼å¼ºåº¦ï¼Œæˆ–ä½¿ç”¨æ›´æ¸…æ™°çš„éŸ³é¢‘æ–‡ä»¶
            - **ç”Ÿæˆç¼“æ…¢**: é™ä½åˆ†è¾¨ç‡ã€å‡å°‘å¸§æ•°æˆ–é‡‡æ ·æ­¥æ•°å¯åŠ å¿«ç”Ÿæˆé€Ÿåº¦
            
            ### æ³¨æ„äº‹é¡¹ï¼š
            - ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²æ­£ç¡®ä¸‹è½½åˆ°æŒ‡å®šè·¯å¾„
            - TIAæ¨¡å¼éœ€è¦æä¾›å‚è€ƒå›¾åƒ
            - éŸ³é¢‘æ–‡ä»¶æ”¯æŒWAVæ ¼å¼
            - ç”Ÿæˆæ—¶é—´å–å†³äºç¡¬ä»¶é…ç½®å’Œå‚æ•°è®¾ç½®
            """)
    
    return interface

if __name__ == "__main__":
    # åˆ›å»ºç•Œé¢
    interface = create_interface()
    
    # å¯åŠ¨åº”ç”¨
    interface.launch(
        server_name="0.0.0.0",
        share=False,
        debug=True,
        show_error=True
    )